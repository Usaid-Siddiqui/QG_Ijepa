{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2GkIlIMSJSAd",
    "outputId": "6668ac5e-4229-4db8-f362-cf51bda62b5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hVCMeT1YSC2s",
    "outputId": "c51cc882-d02f-4437-ed89-29351380ffb7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target file /shared/usiddiqui/IJEPA/data_uncompressed/qg_medium_train.h5 already exists. Skipping.\n",
      "Target file /shared/usiddiqui/IJEPA/data_uncompressed/qq_medium_test.h5 already exists. Skipping.\n",
      "Target file /shared/usiddiqui/IJEPA/data_uncompressed/qg_medium_finetune.h5 already exists. Skipping.\n"
     ]
    }
   ],
   "source": [
    "# We need to decompress the data and store the in chunks optimal for the dataloader to read\n",
    "\n",
    "from utils import unpack_h5\n",
    "unpack_h5(\"/shared/usiddiqui/IJEPA/data_compressed/qg_medium_train.h5\", \"/shared/usiddiqui/IJEPA/data_uncompressed/qg_medium_train.h5\")\n",
    "unpack_h5(\"/shared/usiddiqui/IJEPA/data_compressed/qg_medium_test.h5\", \"/shared/usiddiqui/IJEPA/data_uncompressed/qq_medium_test.h5\")\n",
    "unpack_h5(\"/shared/usiddiqui/IJEPA/data_compressed/qg_medium_finetune.h5\", \"/shared/usiddiqui/IJEPA/data_uncompressed/qg_medium_finetune.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_bCGBLZuL6s3",
    "outputId": "230c6ae5-e23a-46c5-f42e-60ff789b526d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-04 18:25:50,383 | INFO | Config saved to /shared/usiddiqui/IJEPA/checkpoints/vit_small_ijepa_20260204_182550\n",
      "2026-02-04 18:25:50,423 | INFO | --- Dataset Loaded (Size: 100000) ---\n",
      "Epoch 1:   0%|                                       | 0/391 [00:00<?, ?batch/s]^C\n",
      "Epoch 1:   0%|                                       | 0/391 [00:18<?, ?batch/s]\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/shared/usiddiqui/IJEPA/QG_Ijepa/train_pretrain.py\"\u001b[0m, line \u001b[35m85\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    for images, labels, ctx_idx, trg_idx in \u001b[1;31mpbar\u001b[0m:\n",
      "                                            \u001b[1;31m^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/conda/lib/python3.13/site-packages/tqdm/std.py\"\u001b[0m, line \u001b[35m1181\u001b[0m, in \u001b[35m__iter__\u001b[0m\n",
      "    for obj in \u001b[1;31miterable\u001b[0m:\n",
      "               \u001b[1;31m^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/conda/lib/python3.13/site-packages/torch/utils/data/dataloader.py\"\u001b[0m, line \u001b[35m741\u001b[0m, in \u001b[35m__next__\u001b[0m\n",
      "    data = self._next_data()\n",
      "  File \u001b[35m\"/opt/conda/lib/python3.13/site-packages/torch/utils/data/dataloader.py\"\u001b[0m, line \u001b[35m1524\u001b[0m, in \u001b[35m_next_data\u001b[0m\n",
      "    idx, data = \u001b[31mself._get_data\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "                \u001b[31m~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/conda/lib/python3.13/site-packages/torch/utils/data/dataloader.py\"\u001b[0m, line \u001b[35m1473\u001b[0m, in \u001b[35m_get_data\u001b[0m\n",
      "    success, data = \u001b[31mself._try_get_data\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "                    \u001b[31m~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/conda/lib/python3.13/site-packages/torch/utils/data/dataloader.py\"\u001b[0m, line \u001b[35m1310\u001b[0m, in \u001b[35m_try_get_data\u001b[0m\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "  File \u001b[35m\"/opt/conda/lib/python3.13/queue.py\"\u001b[0m, line \u001b[35m210\u001b[0m, in \u001b[35mget\u001b[0m\n",
      "    \u001b[31mself.not_empty.wait\u001b[0m\u001b[1;31m(remaining)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/conda/lib/python3.13/threading.py\"\u001b[0m, line \u001b[35m363\u001b[0m, in \u001b[35mwait\u001b[0m\n",
      "    gotit = waiter.acquire(True, timeout)\n",
      "\u001b[1;35mKeyboardInterrupt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python -u train_pretrain.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zlDpkmpbsvdA"
   },
   "source": [
    "Time for finetuning and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "Fk8E0bOGrtvG",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "24cf903d-2a30-4a28-d9d9-148c959b4dea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training MLP Head | Results path: /content/drive/MyDrive/QG_IJEPA/finetune/vit_small_ijepa_20260203_040412 ---\n",
      "Epoch 1: 100% 313/313 [01:32<00:00,  3.37it/s, acc=0.612, loss=0.644]\n",
      "Epoch 2: 100% 313/313 [01:34<00:00,  3.32it/s, acc=0.638, loss=0.592]\n",
      "Epoch 3: 100% 313/313 [01:34<00:00,  3.30it/s, acc=0.648, loss=0.636]\n",
      "Epoch 4: 100% 313/313 [01:34<00:00,  3.30it/s, acc=0.65, loss=0.557]\n",
      "--- Computing Final ROC AUC ---\n",
      "100% 313/313 [01:34<00:00,  3.30it/s]\n",
      "Figure(800x600)\n",
      "\n",
      "Final AUC: 0.7074\n",
      "Results saved to: /content/drive/MyDrive/QG_IJEPA/finetune/vit_small_ijepa_20260203_040412\n"
     ]
    }
   ],
   "source": [
    "#!python train_finetune.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ML-Venv",
   "language": "python",
   "name": "qg_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
